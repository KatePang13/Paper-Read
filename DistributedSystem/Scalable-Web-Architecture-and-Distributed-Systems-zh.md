# Scalable Web Architecture and Distributed Systems

开源软件已成为一些大型网站的基本构建块。随着这些网站的发展，围绕其架构的最佳做法和指导原则也应运而生。本章旨在涵盖设计大型网站时要考虑的一些关键问题，以及用于实现这些目标的一些构建基块。

本章主要侧重于Web系统，尽管其中一些内容也适用于其他分布式系统。

## 1.1。Web分布式系统设计原理

构建和运行可扩展的网站或应用程序到底意味着什么？在原始级别上，它只是通过Internet将用户与远程资源连接起来-使它具有可伸缩性的部分是资源或对这些资源的访问分布在多个服务器上。

就像生活中的大多数事情一样，在构建Web服务时花点时间进行规划可以从长远来看会有所帮助。理解大型网站背后的一些考虑因素和折衷方案，可以在创建小型网站时做出更明智的决策。以下是一些影响大型Web系统设计的关键原则：

- **可用性：**网站的正常运行时间对于许多公司的声誉和功能至关重要。对于某些较大的在线零售站点而言，即使几分钟之久都不可用，则可能导致数千或数百万美元的收入损失，因此，设计使其系统始终可用并具有抗故障能力的系统是一项基本业务，也是一项技术要求。分布式系统中的高可用性需要仔细考虑关键组件的冗余，在部分系统故障的情况下快速恢复以及出现问题时的正常降级。
- **效果：**网站性能已成为大多数网站的重要考虑因素。网站的速度会影响使用情况和用户满意度，以及搜索引擎排名，这是与收入和保留率直接相关的因素。因此，创建针对快速响应和低延迟而优化的系统至关重要。
- **可靠性：**系统需要可靠，以便对数据的请求将始终返回相同的数据。如果数据发生更改或更新，则该请求应返回新数据。用户需要知道，如果将某些内容写入系统或将其存储，则这些内容将持久存在，并且可以依赖它们放置在将来进行检索。
- **可伸缩性：**对于任何大型分布式系统，规模只是规模方面需要考虑的一个方面。同样重要的是，需要增加容量来处理更大的负载，这通常被称为系统的可伸缩性。可伸缩性可以指系统的许多不同参数：它可以处理多少额外的流量，增加更多存储容量的难易程度，甚至可以处理多少交易。
- **可管理性：**设计一个易于操作的系统是另一个重要的考虑因素。系统的可管理性等同于操作的可伸缩性：维护和更新。可管理性要考虑的事情是问题发生时易于诊断和理解，易于更新或修改以及系统的操作简单性。（即，它是否可以正常运行而不会出现故障或异常？）
- **成本：**成本是一个重要因素。这显然可能包括硬件和软件成本，但是考虑部署和维护系统所需的其他方面也很重要。系统需要花费的开发时间，运行系统所需的操作量，甚至需要的培训量都应考虑在内。成本是总拥有成本。

这些原则中的每一个都为设计分布式Web体系结构中的决策提供了基础。但是，它们也可能彼此矛盾，以至于要实现一个目标就要付出另一个目标的代价。一个基本示例：选择通过简单地添加更多服务器来解决容量问题（可扩展性）可能会以可管理性（您必须操作其他服务器）和成本（服务器的价格）为代价。

设计任何类型的Web应用程序时，重要的是要考虑这些关键原则，即使要承认设计可能会牺牲其中的一个或多个原则。

## 1.2。基础

当涉及到系统体系结构时，需要考虑几件事：什么是正确的部分，这些部分如何组合在一起以及什么是正确的权衡。在需要扩展之前进行投资通常不是明智的业务主张；但是，对设计进行一些预先考虑可以在将来节省大量时间和资源。

本节重点介绍几乎所有大型Web应用程序都至关重要的一些核心因素：*服务*， *冗余*，*分区*和*处理故障*。这些因素中的每一个都涉及选择和折衷，特别是在上一节中描述的原理的上下文中。为了详细解释这些，最好从一个例子开始。

### 示例：图像托管应用程序

在某个时候，您可能已经在线发布了图像。对于承载并交付大量图像的大型站点，构建具有成本效益，高可用性和低延迟（快速检索）的体系结构面临着挑战。

想象一下一个系统，用户可以将其图像上传到中央服务器，并且可以通过Web链接或API来请求图像，就像Flickr或Picasa一样。为了简单起见，让我们假定此应用程序具有两个关键部分：将图像上传（写入）到服务器的能力以及查询图像的能力。尽管我们当然希望上传效率高，但是我们最关心的是在有人请求图像时（例如，可以为网页或其他应用程序请求图像）非常快速地交付。这与Web服务器或内容分发网络（CDN）边缘服务器（CDN服务器用于在许多位置存储内容，因此内容在地理/物理上更接近用户，从而提高性能）所提供的功能非常相似。

该系统的其他重要方面是：

- 对于要存储的图像数量没有限制，因此需要考虑图像数量方面的存储可伸缩性。
- 图像下载/请求的等待时间必须短。
- 如果用户上传图像，则该图像应始终存在（图像的数据可靠性）。
- 该系统应易于维护（可管理性）。
- 由于图像托管的利润率不高，因此该系统必须具有成本效益

[图1.1](http://www.aosabook.org/en/distsys.html#fig.distsys.1)是该功能的简化图。

![img](http://www.aosabook.org/images/distsys/imageHosting1.jpg)图1.1：图像托管应用程序的简化架构图

在此图像托管示例中，系统必须可感知到快速，可靠地存储其数据并且所有这些属性都具有高度可伸缩性。构建此应用程序的小版本非常容易，并且可以轻松地托管在单个服务器上；但是，对于本章而言，这并没有什么意义。假设我们要构建的东西可能会和Flickr一样大。

### 服务

在考虑可伸缩系统设计时，它有助于分离功能，并通过明确定义的界面将系统的每个部分视为自己的服务。实际上，以这种方式设计的系统据说具有面向服务的体系结构（SOA）。对于这些类型的系统，每个服务都有其自己独特的功能上下文，并且与该上下文之外的任何内容的交互都是通过抽象接口（通常是另一个服务的面向公众的API）进行的。

将系统解构为一组补充服务可以使这些组件的操作彼此分离。这种抽象有助于在服务，其基础环境以及该服务的使用者之间建立明确的关系。创建这些清晰的轮廓可以帮助隔离问题，但也可以使每一部分相互独立缩放。系统的这种面向服务的设计与编程的面向对象的设计非常相似。

在我们的示例中，所有上传和检索图像的请求均由同一服务器处理；但是，由于系统需要扩展，因此有必要将这两个功能分解为自己的服务。

快进并假设该服务已大量使用；这样的场景使您很容易看到写入的时间会影响读取图像的时间（因为这两个功能将争夺共享资源）。根据架构的不同，这种影响可能很大。即使上载和下载速度相同（对于大多数IP网络而言，情况并非如此，因为大多数IP网络是为至少3：1的下载速度：上载速度的比率而设计的），读取的文件通常也会从缓存中读取，并且最终将不得不将数据写入磁盘（并且在最终一致的情况下可能要写入多次）。即使所有内容都在内存中或从磁盘（如SSD）读取，数据库写入几乎总是比读取速度慢。（Pole Position，一种用于数据库基准测试的开源工具， [http：//polepos.org/](http://polepos.org/)和结果 http://polepos.sourceforge.net/results/PolePositionClientServer.pdf。）。

此设计的另一个潜在问题是，像Apache或lighttpd这样的Web服务器通常对其可以保持的同时连接数有一个上限（默认值约为500，但可能更高），并且在高流量中，写入会很快消耗掉所有这些。由于读取可以是异步的，也可以利用其他性能优化（例如gzip压缩或分块传输编码）的优势，因此Web服务器可以更快地切换服务读取，并且可以在客户端之间快速切换，以每秒服务的请求数量超过最大连接数（使用Apache和最大连接数设置为500，通常每秒可以处理数千个读取请求）。另一方面，写入倾向于在上传期间保持开放连接，

![img](http://www.aosabook.org/images/distsys/imageHosting2.png)图1.2：拆分读取和写入

为这种瓶颈进行计划是一个很好的案例，可以将图像的读写分为各自的服务，如图[1.2](http://www.aosabook.org/en/distsys.html#fig.distsys.2)所示。这使我们能够独立地缩放它们中的每一个（因为我们可能总是会做更多的阅读而不是写作），而且还有助于弄清每一点的情况。最后，这将将来的问题分开，这将使故障排除和扩展问题（例如读取速度慢）更加容易。

这种方法的优势在于，我们能够彼此独立地解决问题-我们不必担心在同一上下文中编写和检索新图像。这两种服务仍然利用全球图像库，但是它们可以使用适合服务的方法（例如，排队请求或缓存流行图像，下面将对此进行详细介绍）自由地优化自身性能。从维护和成本的角度来看，每项服务都可以根据需要独立扩展，这非常好，因为如果将它们组合并混合在一起，则一个服务可能会无意中影响另一个服务的性能，如上面所讨论的情形。

当然，当您有两个不同的端点时，上述示例可以很好地工作（实际上，这与几个云存储提供商的实现和内容交付网络非常相似）。但是，有很多方法可以解决这些类型的瓶颈，并且每种方法都有不同的权衡。

例如，Flickr通过将用户分布在不同的分片上来解决此读/写问题，这样每个分片只能处理一定数量的用户，并且随着用户数量的增加，更多分片将添加到集群中（请参阅有关Flickr扩展的演示 [http： //mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html](http://mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html)）。在第一个示例中，更容易根据实际使用量（整个系统的读写次数）来扩展硬件，而Flickr随其用户群进行扩展（但会强制假设整个用户的使用量相等，因此可能会有额外的容量） ）。在前一种情况下，其中一项服务出现故障或出现问题会降低整个系统的功能（例如，没有人可以写入文件），而使用Flickr碎片之一的中断只会影响这些用户。在第一个示例中，更容易在整个数据集中执行操作-例如，

对于这些系统，没有正确的答案，但是可以帮助您回到本章开始的原则，确定系统需求（大量读写操作，并发级别，跨数据集的查询，范围，排序等），对不同的替代方案进行基准测试，了解系统将如何发生故障，并为发生故障的时间制定可靠的计划。

### 冗余

为了优雅地处理故障，Web体系结构必须具有其服务和数据的冗余。例如，如果在单个服务器上仅存储一个文件的副本，则丢失该服务器意味着丢失该文件。丢失数据很少是一件好事，而处理数据的常见方法是创建多个或冗余的副本。

同样的原则也适用于服务。如果应用程序具有核心功能，则确保同时运行多个副本或版本可以确保避免单个节点发生故障。

在系统中创建冗余可以消除单点故障，并在危机中需要时提供备份或备用功能。例如，如果生产中正在运行同一服务的两个实例，而一个实例发生故障或降级，则系统可以*故障转移* 到正常副本。故障转移可以自动发生或需要手动干预。

服务冗余的另一个关键部分是创建无*共享架构*。通过这种体系结构，每个节点都可以彼此独立地运行，并且没有中央“大脑”管理其他节点的状态或协调活动。由于可以在没有特殊条件或知识的情况下添加新节点，因此可伸缩性大有帮助。但是，最重要的是，这些系统中没有单点故障，因此它们对故障具有更大的弹性。

例如，在我们的图像服务器应用程序中，所有图像将在某处的另一块硬件上具有冗余副本（如果发生灾难，例如在数据中心发生地震或火灾，最好在不同的地理位置），并提供访问服务这些图像将是多余的，所有潜在的服务请求。（请参 [见图1.3](http://www.aosabook.org/en/distsys.html#fig.distsys.3)。）（负载均衡器是实现此目标的好方法，但下面还有更多内容）。

![img](http://www.aosabook.org/images/distsys/imageHosting3.png)图1.3：具有冗余功能的映像托管应用程序

### 分区

可能有非常大的数据集无法容纳在单个服务器上。也可能是一种操作需要太多的计算资源，降低性能并有必要增加容量的情况。无论哪种情况，您都有两种选择：垂直缩放或水平缩放。

纵向扩展意味着向单个服务器添加更多资源。因此，对于非常大的数据集，这可能意味着添加更多（或更大）的硬盘驱动器，以便单个服务器可以包含整个数据集。对于计算操作，这可能意味着将计算移到具有更快CPU或更多内存的更大服务器上。在每种情况下，垂直扩展都是通过使单个资源能够自行处理更多资源来实现的。

另一方面，水平缩放就是添加更多节点。对于大型数据集，这可能是用于存储部分数据集的第二台服务器，对于计算资源而言，这意味着将操作拆分或分配给其他一些节点。为了充分利用水平缩放，应将其作为系统体系结构的固有设计原则包括在内，否则修改和分离上下文以使其成为可能可能非常麻烦。

当涉及到水平扩展时，较常见的技术之一是将服务分解为分区或分片。可以分布分区，以使每个逻辑功能集都是独立的。这可以通过地理边界来完成，也可以通过其他条件（例如，非付费用户还是付费用户）来完成。这些方案的优点是它们为服务或数据存储提供了增加的容量。

在我们的图像服务器示例中，用于存储图像的单个文件服务器可能被多个文件服务器代替，每个文件服务器都包含自己的唯一图像集。（请参阅[图1.4](http://www.aosabook.org/en/distsys.html#fig.distsys.4)。）这样的体系结构将允许系统用映像填充每个文件服务器，并在磁盘已满时添加其他服务器。设计将需要一种命名方案，将图像的文件名绑定到包含该文件名的服务器。映像名称可以由跨服务器映射的一致哈希方案形成。或者，可以为每个图像分配一个增量ID，以便当客户端请求图像时，图像检索服务仅需要维护映射到每个服务器的ID范围（如索引）。

![img](http://www.aosabook.org/images/distsys/imageHosting4.png)图1.4：具有冗余和分区功能的映像托管应用程序

当然，跨多个服务器分布数据或功能也存在挑战。关键问题之一是*数据局部性*；在分布式系统中，数据离操作或计算点越近，系统的性能越好。因此，将数据分布在多个服务器上可能存在问题，因为任何时候它可能都不是本地的，从而迫使服务器在网络上执行所需信息的昂贵获取。

另一个潜在的问题是*不一致*的形式 。如果从共享资源（可能是另一个服务或数据存储）中读取和写入不同的服务，则有可能出现竞争情况（本来应该更新某些数据，但读取发生在更新之前），在这种情况下数据不一致。例如，在图像托管方案中，如果一个客户端发送了一个使用新标题更新狗图像的请求，将其从“ Dog”更改为“ Gizmo”，则可能发生竞争状况，但与此同时，另一个客户端正在读取图片。在这种情况下，尚不清楚第二个客户将收到哪个标题“ Dog”或“ Gizmo”。

数据分区当然存在一些障碍，但是分区允许将每个问题（按数据，负载，使用模式等）拆分为可管理的块。这可以帮助实现可伸缩性和可管理性，但并非没有风险。有很多减轻风险和处理故障的方法。但是，为了简洁起见，本章不介绍它们。如果您有兴趣阅读更多内容，可以查看我[的](http://katemats.com/2011/11/13/distributed-systems-basics-handling-failure-fault-tolerance-and-monitoring/) 有关容错和监视的[博客文章](http://katemats.com/2011/11/13/distributed-systems-basics-handling-failure-fault-tolerance-and-monitoring/)。

## 1.3。快速和可扩展的数据访问的基础

涵盖了设计分布式系统时的一些核心考虑因素后，现在让我们讨论最困难的部分：扩展对数据的访问。

大多数简单的Web应用程序（例如LAMP堆栈应用程序）的外观[如图1.5所示](http://www.aosabook.org/en/distsys.html#fig.distsys.5)。

![img](http://www.aosabook.org/images/distsys/simpleWeb.png)图1.5：简单的Web应用程序

随着它们的增长，存在两个主要挑战：扩展对应用程序服务器和数据库的访问。在高度可扩展的应用程序设计中，通常将应用程序（或Web）服务器最小化，并且通常体现为无共享架构。这使得系统的应用服务器层可以水平扩展。这种设计的结果是，繁重的工作被压低了栈，直达数据库服务器和支持服务。在这一层，真正的扩展性和性能挑战开始发挥作用。

本章的其余部分专门介绍一些更常见的策略和方法，这些方法和方法通过提供对数据的快速访问来使这些类型的服务快速且可扩展。

![img](http://www.aosabook.org/images/distsys/overSimpleWeb.png)图1.6：简化的Web应用程序

大多数系统可以简化为[图1.6](http://www.aosabook.org/en/distsys.html#fig.distsys.6)。这是一个很好的起点。如果您有大量数据，则需要快速简便地访问，例如将糖果藏在办公桌的顶部抽屉中。尽管过分简化，但先前的声明提示了两个难题：存储的可伸缩性和数据的快速访问。

为了本节的缘故，让我们假设您有许多TB的数据，并且希望允许用户随机访问该数据的一小部分。（请参阅[图1.7](http://www.aosabook.org/en/distsys.html#fig.distsys.7)。）这类似于在图像应用程序示例中将图像文件放置在文件服务器上的某个位置。

![img](http://www.aosabook.org/images/distsys/accessingData.png)图1.7：访问特定数据

这特别具有挑战性，因为将TB的数据加载到内存可能会非常昂贵。这直接转换为磁盘IO。从磁盘读取比从内存读取慢许多倍—内存访问的速度与Chuck Norris一样快，而磁盘访问的速度比DMV处的速度慢。对于大型数据集，这种速度差异确实加在一起。以实数表示，顺序读取的内存访问速度比从磁盘读取的速度快6倍，而随机读取速度则快100,000倍（请参阅“大数据的病理学”，[http：//queue.acm.org/detail。 cfm？id = 1563874](http://queue.acm.org/detail.cfm?id=1563874)）。而且，即使具有唯一的ID，解决知道在哪里找到少量数据的问题也是一项艰巨的任务。就像试图从糖果盒中获取最后的Jolly Rancher一样，不看。

值得庆幸的是，您可以使用许多选项来简化此操作。较重要的四个是缓存，代理，索引和负载平衡器。本节的其余部分讨论如何使用这些概念中的每一个来使数据访问快得多。

### 快取

缓存利用了引用原则的局部性：最近请求的数据可能会再次被请求。它们几乎用于计算的每个层：硬件，操作系统，Web浏览器，Web应用程序等等。高速缓存就像短期内存：它具有有限的空间量，但是通常比原始数据源快，并且包含最近访问的项目。缓存可以存在于体系结构的所有级别，但通常位于最接近前端的级别，在缓存的实现是为了快速返回数据而不会增加下游级别的负担。

在我们的API示例中，如何使用缓存来使您的数据访问更快？在这种情况下，您可以在几个地方插入缓存。一种选择是在请求层节点上插入缓存， [如图1.8所示](http://www.aosabook.org/en/distsys.html#fig.distsys.8)。

![img](http://www.aosabook.org/images/distsys/cache.png)图1.8：在请求层节点上插入缓存

将缓存直接放置在请求层节点上可以实现响应数据的本地存储。每次对服务提出请求时，节点将快速返回本地缓存的数据（如果存在）。如果它不在高速缓存中，则请求节点将从磁盘查询数据。一个请求层节点上的缓存也可以位于内存（速度非常快）和节点的本地磁盘上（比进入网络存储更快）。

![img](http://www.aosabook.org/images/distsys/multipleCaches.png)图1.9：多个缓存

将其扩展到许多节点时会发生什么？正如你可以看到[图1.9](http://www.aosabook.org/en/distsys.html#fig.distsys.9)，如果该请求层扩展到多个节点，它仍然是完全有可能的每个节点的主机自己的缓存。但是，如果您的负载均衡器在节点之间随机分配请求，则相同的请求将到达不同的节点，从而增加了缓存丢失率。克服此障碍的两个选择是全局缓存和分布式缓存。

### 全局缓存

听起来就像是全局缓存：所有节点都使用相同的单个缓存空间。这涉及到以比原始存储更快的速度添加服务器或某种文件存储，并且可由所有请求层节点访问。每个请求节点以与本地请求相同的方式查询缓存。这种缓存方案可能会变得有点复杂，因为随着客户端和请求数量的增加，很容易使单个缓存不堪重负，但是在某些架构（尤其是那些具有专用硬件的架构）中非常有效，这种架构可以使此全局缓存非常快，或具有需要缓存的固定数据集）。

图中描绘了两种通用形式的全局缓存。在[图1.10中](http://www.aosabook.org/en/distsys.html#fig.distsys.10)，当在缓存中找不到缓存的响应时，缓存本身将负责从基础存储中检索丢失的数据。在[图1.11中](http://www.aosabook.org/en/distsys.html#fig.distsys.11) ，请求节点负责检索在缓存中找不到的任何数据。

![img](http://www.aosabook.org/images/distsys/globalCache1.png)图1.10：全局缓存，其中缓存负责检索

![img](http://www.aosabook.org/images/distsys/globalCache2.png)图1.11：全局缓存，其中请求节点负责检索

利用全局高速缓存的大多数应用程序倾向于使用第一种类型，其中高速缓存本身负责管理逐出和获取数据，以防止来自客户端的对相同数据的请求泛滥。但是，在某些情况下，第二种实现更有意义。例如，如果将高速缓存用于非常大的文件，则较低的高速缓存命中百分比将导致高速缓存缓冲区因高速缓存未命中而变得不堪重负；在这种情况下，有助于在缓存中拥有总数据集（或热数据集）的很大一部分。另一个例子是一种架构，其中存储在缓存中的文件是静态的，不应驱逐。

### 分布式缓存

在分布式缓存中（[图1.12](http://www.aosabook.org/en/distsys.html#fig.distsys.12)），每个节点都拥有部分缓存数据，因此，如果冰箱充当杂货店的缓存，则分布式缓存就像将食物放在多个位置（冰箱，橱柜，*和*便当盒-方便的位置，可从商店取回小吃，而无需前往商店。通常，使用一致的哈希函数对高速缓存进行划分，这样，如果请求节点正在查找某个数据，它可以快速知道在分布式高速缓存中查找的位置，以确定该数据是否可用。在这种情况下，每个节点都有一小部分缓存，然后将在发送到原始节点之前向另一个节点发送数据请求。因此，分布式缓存的优点之一是增加缓存空间，仅通过将节点添加到请求池即可拥有该缓存空间。

分布式缓存的一个缺点是补救丢失的节点。一些分布式缓存通过在不同节点上存储数据的多个副本来解决此问题。但是，您可以想象这种逻辑如何迅速变得复杂，尤其是当您从请求层添加或删除节点时。尽管即使一个节点消失并且部分缓存丢失，请求也只会从源中拉出-因此不一定是灾难性的！

![img](http://www.aosabook.org/images/distsys/distributedCaching.png)图1.12：分布式缓存

缓存的妙处在于，它们通常可使处理速度更快（当然，实现正确！）。您选择的方法仅使您可以更快地处理更多请求。但是，所有这些缓存都以必须维护额外的存储空间为代价，通常以昂贵的内存形式存在。没有什么是免费的。高速缓存对于使整体运行速度更快而言非常有用，而且可以在高负载条件下提供系统功能，否则将导致服务完全降级。

流行的开源缓存的一个示例是Memcached（http://memcached.org/）（它既可以用作本地缓存，也可以用作分布式缓存）。但是，还有许多其他选项（包括许多特定于语言或框架的选项）。

Memcached已在许多大型网站中使用，尽管它可能非常强大，但它只是一个内存中键值存储，针对任意数据存储和快速查找进行了优化（*O（1）*）。

Facebook使用几种不同类型的缓存来获取其网站性能（请参阅“ [Facebook缓存和性能”](http://sizzo.org/talks/)）。他们`$GLOBALS`在语言级别使用和APC缓存（在PHP中以函数调用为代价提供），这有助于进行中间函数调用，并且结果更快。（大多数语言都具有这些类型的库来提高网页性能，因此几乎应始终使用它们。）然后，Facebook使用分布在许多服务器上的全局缓存（请参阅“ [在Facebook上扩展内存缓存”）](http://www.facebook.com/note.php?note_id=39391378919)），这样一个函数调用就可以访问缓存，从而并行请求存储在不同Memcached服务器上的数据。这使他们能够为其用户配置文件数据获得更高的性能和吞吐量，并拥有一个集中的位置来更新数据（这很重要，因为当您运行数千台服务器时，缓存失效和保持一致性可能会面临挑战）。

现在让我们谈谈当数据不在缓存中时该怎么办……

### 代理人

从根本上讲，代理服务器是硬件/软件的中间部分，用于接收来自客户端的请求并将其中继到后端原始服务器。通常，代理用于过滤请求，日志请求或有时转换请求（通过添加/删除头，加密/解密或压缩）。

![img](http://www.aosabook.org/images/distsys/proxies.png)图1.13：代理服务器

当协调来自多个服务器的请求时，代理也非常有用，从系统范围的角度来看，代理可以优化请求流量。使用代理加速数据访问的一种方法是将相同（或相似）的请求折叠成一个请求，然后将单个结果返回给发出请求的客户端。这称为崩溃转发。

想象一下，在多个节点上都需要相同的数据（我们称其为littleB），并且该数据不在缓存中。如果该请求通过代理路由，则所有这些请求都可以折叠为一个，这意味着我们只需要从磁盘读取littleB一次。（请参[见图1.14](http://www.aosabook.org/en/distsys.html#fig.distsys.14)。）与该设计相关联的是一些成本，因为每个请求的延迟可能会稍高一些，并且某些请求可能会稍有延迟以与相似的请求分组。但是，它将提高高负载情况下的性能，尤其是当一遍又一遍地请求相同的数据时。这类似于缓存，但是与其像缓存一样存储数据/文档，不如优化对这些文档的请求或调用，并充当这些客户端的代理。

例如，在LAN代理中，客户端不需要其自己的IP即可连接到Internet，并且LAN将折叠来自客户端的相同内容的呼叫。但是，由于许多代理服务器也是高速缓存（这是放置高速缓存的非常合逻辑的地方），因此在这里很容易混淆，但是并非所有高速缓存都充当代理。

![img](http://www.aosabook.org/images/distsys/collapseRequests.png)图1.14：使用代理服务器折叠请求

使用代理的另一种好方法是不仅折叠对相同数据的请求，而且折叠对原始存储区（连续地在磁盘上）在空间上靠近的数据的请求。采用这种策略可使请求的数据局部性最大化，从而可减少请求等待时间。例如，假设一堆节点请求B的一部分：partB1，partB2等。我们可以设置代理以识别单个请求的空间位置，将它们折叠成单个请求并仅返回bigB，从而极大地减少了从数据源读取。（[见图1.15](http://www.aosabook.org/en/distsys.html#fig.distsys.15)。）当您跨TB数据随机访问时，这可能在请求时间上产生很大的不同！代理在高负载情况下或缓存有限时特别有用，因为它们实际上可以将多个请求批量处理为一个。

![img](http://www.aosabook.org/images/distsys/collapseRequestsSpatial.png)图1.15：使用代理折叠空间上靠近的数据请求

值得注意的是，可以将代理和缓存一起使用，但是通常最好将缓存放在代理服务器的前面，出于同样的原因，最好让速度更快的跑步者在拥挤的马拉松比赛中首先开始。这是因为高速缓存正在从内存中提供数据，它非常快，并且它不介意针对相同结果的多个请求。但是，如果缓存位于代理服务器的另一侧，则缓存之前的每个请求都会有额外的延迟，这可能会降低性能。

如果您正在考虑向系统中添加代理，则可以考虑许多选项。 [Squid](http://www.squid-cache.org/)和 [Varnish](https://www.varnish-cache.org/)都经过了路测，并在许多生产网站中得到广泛使用。这些代理解决方案提供了许多优化功能，以充分利用客户端与服务器之间的通信。在Web服务器层上安装其中之一作为反向代理（在下面的负载均衡器部分中有说明）可以显着提高Web服务器的性能，从而减少处理传入的客户端请求所需的工作量。

### 指标

使用索引快速访问数据是优化数据访问性能的众所周知的策略。关于数据库，可能是最著名的。索引需要权衡增加的存储开销和较慢的写入速度（因为必须同时写入数据和更新索引），以利于更快的读取速度。

就像传统的关系数据存储一样，您也可以将此概念应用于更大的数据集。使用索引的诀窍是您必须仔细考虑用户将如何访问您的数据。在数据集的大小为许多TB，但有效载荷非常小（例如1 KB）的情况下，索引是优化数据访问的必要条件。在如此大的数据集中找到较小的有效载荷可能是一个真正的挑战，因为您可能无法在任何合理的时间内迭代大量的数据。此外，如此大的数据集很可能分布在几个（或多个！）物理设备上-这意味着您需要某种方式来找到所需数据的正确物理位置。索引是执行此操作的最佳方法。

![img](http://www.aosabook.org/images/distsys/indexes.jpg)图1.16：索引

索引可以像目录一样使用，将您定向到数据所在的位置。例如，假设您正在寻找一段数据，即B的第2部分-您将如何知道在哪里找到它？如果您有一个按数据类型排序的索引（例如数据A，B，C），它将告诉您数据B在原点的位置。然后，您只需要寻找该位置并阅读所需的B部分即可。（参见[图1.16](http://www.aosabook.org/en/distsys.html#fig.distsys.16)。）

这些索引通常存储在内存中，或者对于传入的客户端请求来说非常本地。伯克利DB（BDB）和树状数据结构通常用于将数据存储在有序列表中，非常适合使用索引进行访问。

通常，有许多层索引用作地图，将您从一个位置移动到另一个位置，依此类推，直到获得所需的特定数据为止。（参见[图1.17](http://www.aosabook.org/en/distsys.html#fig.distsys.17)。）

![img](http://www.aosabook.org/images/distsys/multipleIndexes.jpg)图1.17：多层索引

索引也可以用于创建同一数据的多个不同视图。对于大型数据集，这是定义不同过滤器和排序的好方法，而无需诉诸于创建许多其他数据副本。

例如，假设以前的图像托管系统实际上是托管书页的图像，并且该服务允许客户端查询这些图像中的文本，搜索有关某个主题的所有书籍内容，搜索引擎可以使您搜索HTML内容。在这种情况下，所有这些书籍图像都需要许多服务器来存储文件，并且找到一页要呈现给用户的内容可能会有些麻烦。首先，用于查询任意单词和单词元组的逆索引必须易于访问；那么就面临着导航到该书中确切的页面和位置并为结果检索正确图像的挑战。因此，在这种情况下，倒排索引将映射到一个位置（例如书B），然后B可能包含一个索引，其中包含每个部分中的所有单词，位置和出现次数。

可以在上图中表示Index1的倒排索引可能看起来类似于以下内容-每个单词或单词元组提供了包含哪些书籍的索引。

| 话） | 图书）              |
| :--- | :------------------ |
| 很棒 | 书籍B，书籍C，书籍D |
| 总是 | 书籍C，书籍F        |
| 相信 | 书B                 |

中间索引看起来很相似，但只包含书B的单词，位置和信息。这种嵌套索引架构允许这些索引中的每一个占用的空间都比必须将所有信息都存储到一个大的反向索引中要少。 。

这在大型系统中很关键，因为即使压缩，这些索引也可能变得相当大且存储昂贵。在此系统中，如果我们假设世界上有很多图书-100,000,000（请参阅[Inside Google Books](http://booksearch.blogspot.com/2010/08/books-of-world-stand-up-and-be-counted.html)博客文章），并且每本书只有10页长（为了使数学更容易），每页250个单词，这意味着有2500亿字。如果我们假设每个单词平均5个字符，并且每个字符占用8位（或1个字节，即使某些字符为2个字节），那么每个单词5个字节，那么仅包含每个单词一次的索引就超过了TB的TB。存储。因此，您可以看到创建具有很多其他信息（如单词元组，数据位置和出现次数）的索引的过程非常迅速。

创建这些中间索引并在较小的部分中表示数据将使大数据问题变得易于处理。数据可以分布在许多服务器上，并且仍然可以快速访问。索引是信息检索的基石，也是当今现代搜索引擎的基础。当然，本节仅涉及表面知识，并且进行了许多有关如何使索引更小，更快，包含更多信息（如相关性）以及无缝更新的研究。（竞争条件以及添加新数据或更改现有数据所需的大量更新都存在一些可管理性挑战，特别是在涉及相关性或计分的情况下）。

能够快速轻松地找到您的数据很重要；索引是实现此目标的有效且简单的工具。

### 负载均衡器

最后，任何分布式系统的另一个关键部分是负载均衡器。负载均衡器是任何体系结构的主要组成部分，因为它们的作用是在负责服务请求的一组节点之间分配负载。这允许多个节点透明地服务系统中的同一功能。（请参[见图1.18](http://www.aosabook.org/en/distsys.html#fig.distsys.18)。）它们的主要目的是处理大量同时连接，并将这些连接路由到请求节点之一，从而允许系统仅通过添加节点即可扩展以服务更多请求。

![img](http://www.aosabook.org/images/distsys/loadBalancer.png)图1.18：负载均衡器

有许多不同的算法可用于处理请求，包括选择随机节点，循环轮询，甚至根据某些标准（例如内存或CPU利用率）选择节点。负载均衡器可以实现为软件或硬件设备。[HAProxy](http://haproxy.1wt.eu/)是一种已被广泛采用的开源软件负载平衡器 。

在分布式系统中，负载平衡器通常位于系统的最前端，因此所有传入的请求都将相应地路由。在复杂的分布式系统中，将请求路由到多个负载均衡器的情况并不少见，[如图1.19](http://www.aosabook.org/en/distsys.html#fig.distsys.19)所示 。

![img](http://www.aosabook.org/images/distsys/multipleLoadBalancers.png)图1.19：多个负载均衡器

像代理一样，某些负载平衡器还可以根据请求的类型来不同地路由请求。（从技术上讲，这些也称为反向代理。）

负载平衡器的挑战之一是管理特定于用户会话的数据。在一个电子商务站点中，当您只有一个客户时，很容易允许用户将商品放入购物车并在访问之间保留这些内容（这很重要，因为如果有以下情况，您将更有可能出售产品）当用户返回时，它仍然在用户的购物车中）。但是，如果将用户路由到一个节点进行会话，然后在下次访问时将其路由到另一个节点，则可能会出现不一致，因为新节点可能会丢失该用户的购物车内容。（如果您在购物车中放了6包Mountain Dew，然后又回来又空了，您会不会感到烦恼？）一种解决方法是使会话保持粘性，以便始终将用户路由到同一节点，但是很难利用一些可靠性功能，例如自动故障转移。在这种情况下，用户的购物车将始终具有内容，但是如果他们的粘性节点不可用，则将需要特殊情况，并且其中内容的假设将不再有效（尽管希望该假设不会有效）内置到应用程序中）。当然，可以使用本章中的其他策略和工具（例如服务）解决许多问题（例如浏览器缓存，cookie和URL重写），这些服务可以解决。但是，如果他们的粘性节点不可用，则需要有一种特殊情况，并且内容存在的假设将不再有效（尽管希望该假设不会内置到应用程序中）。当然，可以使用本章中的其他策略和工具（例如服务）解决许多问题（例如浏览器缓存，cookie和URL重写），这些服务可以解决。但是，如果他们的粘性节点不可用，则需要有一种特殊情况，并且内容存在的假设将不再有效（尽管希望该假设不会内置到应用程序中）。当然，可以使用本章中的其他策略和工具（例如服务）解决许多问题（例如浏览器缓存，cookie和URL重写），这些服务可以解决。

如果系统只有几个节点，则循环DNS之类的系统可能更有意义，因为负载均衡器可能很昂贵，并且会增加不必要的复杂性。当然，在较大的系统中，存在各种不同的调度和负载平衡算法，包括简单的算法（例如随机选择或轮询），以及更复杂的机制，其中要考虑利用率和容量。所有这些算法都允许分发流量和请求，并可以提供有用的可靠性工具，例如自动故障转移或自动删除不良节点（例如，当它变得无响应时）。但是，这些高级功能会使问题诊断变得麻烦。例如，在高负载情况下，负载平衡器将删除可能会变慢或超时（由于请求过多）的节点，但这只会加剧其他节点的情况。在这些情况下，广泛的监视非常重要，因为整个系统的流量和吞吐量可能看起来正在下降（因为节点为更少的请求提供服务），但各个节点却变得越来越繁忙。

负载平衡器是一种允许您扩展系统容量的简单方法，并且像本文中的其他技术一样，在平衡分布式系统体系结构中起着至关重要的作用。负载平衡器还提供了能够测试节点运行状况的关键功能，这样，如果一个节点无响应或过载，则可以利用池中不同节点的冗余性将其从池处理请求中删除。系统。

### Queue列

到目前为止，我们已经介绍了许多快速读取数据的方法，但是扩展数据层的另一个重要部分是有效的写入管理。当系统简单，处理负荷最小且数据库较小时，写入速度可以预期地快速；但是，在更复杂的系统中，写入可能要花费几乎不确定的长时间。例如，可能必须将数据写入不同服务器或索引上的多个位置，否则系统可能正处于高负载状态。如果写入或与此相关的任何任务可能需要很长时间，则要实现性能和可用性，就需要在系统中建立异步机制。常见的做法是使用队列。

![img](http://www.aosabook.org/images/distsys/synchronousRequest.png)图1.20：同步请求

想象一下一个系统，其中每个客户端都在请求一项任务以进行远程服务。这些客户端中的每个客户端都将其请求发送到服务器，服务器在该服务器上尽快完成任务并将结果返回给各自的客户端。在小型系统中，一台服务器（或逻辑服务）可以为传入的客户端提供最快的服务，这种情况应该可以正常工作。但是，当服务器收到的请求超出其处理能力的范围时，每个客户端将被迫等待其他客户端的请求完成，然后才能生成响应。这是同步请求的示例，[如图1.20所示](http://www.aosabook.org/en/distsys.html#fig.distsys.20)。

这种同步行为会严重降低客户端性能。客户端被迫等待，有效地执行零工作，直到可以响应其请求。添加额外的服务器来解决系统负载也无法解决问题。即使有效地实现了负载平衡，也很难确保最大程度地提高客户绩效所需的工作的公平分配。此外，如果处理请求的服务器不可用或失败，则上游客户端也将失败。有效地解决此问题需要抽象客户请求和为该请求执行的实际工作。

![img](http://www.aosabook.org/images/distsys/queues.png)图1.21：使用队列管理请求

输入队列。队列听起来很简单：一个任务进来，添加到队列中，然后工作人员有能力处理下一个任务，因此接起下一个任务。（请参[见图1.21](http://www.aosabook.org/en/distsys.html#fig.distsys.21)。）这些任务可能表示对数据库的简单写入，或者与为文档生成缩略图预览图像一样复杂。当客户将任务请求提交到队列时，他们不再被迫等待结果。相反，他们只需要确认已正确接收到请求即可。当客户需要时，此确认以后可以用作工作结果的参考。

队列使客户端能够以异步方式工作，从而提供了对客户端请求及其响应的战略抽象。另一方面，在同步系统中，请求和答复之间没有区别，因此不能单独管理它们。在异步系统中，客户端请求任务，服务以确认已接收到任务的消息作为响应，然后客户端可以定期检查任务的状态，仅在完成后才请求结果。在客户端等待异步请求完成时，它可以自由执行其他工作，甚至可以发出其他服务的异步请求。后者是在分布式系统中如何利用队列和消息的示例。

队列还为服务中断和故障提供了一些保护。例如，创建一个高度健壮的队列很容易，它可以重试由于瞬时服务器故障而失败的服务请求。与将客户端直接暴露给间歇性服务中断相比，使用队列执行服务质量保证要好得多，因为后者需要复杂且经常不一致的客户端错误处理。

队列是管理任何大型分布式系统的不同部分之间的分布式通信的基础，并且有很多方法可以实现它们。有很多开源队列，例如[RabbitMQ](http://www.rabbitmq.com/)， [ActiveMQ](http://activemq.apache.org/)， [BeanstalkD](http://kr.github.com/beanstalkd/)，但也有一些使用[Zookeeper之类的](http://zookeeper.apache.org/)服务，甚至使用 [Redis之](http://redis.io/)类的数据存储。

## 1.4。结论

设计能够快速访问大量数据的高效系统非常令人兴奋，并且有许多出色的工具可以启用各种新应用程序。本章仅介绍了几个示例，几乎没有涉及任何内容，但还有更多示例，并且该领域将继续有更多创新。